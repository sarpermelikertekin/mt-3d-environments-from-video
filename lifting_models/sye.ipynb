{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define the Pose Estimation Model\n",
    "class PoseEstimationNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(PoseEstimationNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(512, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class ObjectDatasetByID(Dataset):\n",
    "    def __init__(self, data_2d_path, data_3d_path):\n",
    "        self.data_by_id = defaultdict(lambda: {\"2d\": [], \"3d\": []})\n",
    "        self.expected_output_size = 31  # Expected output size based on structure\n",
    "\n",
    "        files_2d = sorted([f for f in os.listdir(data_2d_path) if f.endswith('.csv')])\n",
    "        \n",
    "        for file_2d in files_2d:\n",
    "            data_2d_file_path = os.path.join(data_2d_path, file_2d)\n",
    "            data_3d_file_path = os.path.join(data_3d_path, file_2d)\n",
    "\n",
    "            if not os.path.exists(data_3d_file_path):\n",
    "                print(f\"Skipping; 3D file missing for: {file_2d}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                df_2d = pd.read_csv(data_2d_file_path, header=None)\n",
    "                df_3d = pd.read_csv(data_3d_file_path, header=None)\n",
    "\n",
    "                if len(df_2d) != len(df_3d):\n",
    "                    print(f\"Skipping; row count mismatch in files: {file_2d}\")\n",
    "                    continue\n",
    "                if df_3d.shape[1] != self.expected_output_size:\n",
    "                    print(f\"Skipping; 3D data size mismatch for file {file_2d}\")\n",
    "                    continue\n",
    "\n",
    "                for row_2d, row_3d in zip(df_2d.values, df_3d.values):\n",
    "                    obj_id = int(row_2d[0])  # First column is the ID\n",
    "                    self.data_by_id[obj_id][\"2d\"].append(torch.tensor(row_2d[1:], dtype=torch.float32)) \n",
    "                    self.data_by_id[obj_id][\"3d\"].append(torch.tensor(row_3d[1:], dtype=torch.float32))\n",
    "\n",
    "            except (pd.errors.EmptyDataError, ValueError):\n",
    "                print(f\"Skipping invalid file pair: {file_2d}\")\n",
    "\n",
    "    def get_data_by_id(self):\n",
    "        # Returns the data separated by ID\n",
    "        return {obj_id: (torch.stack(data[\"2d\"]), torch.stack(data[\"3d\"]))\n",
    "                for obj_id, data in self.data_by_id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, data_loader, criterion, device='cpu'):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(data_loader)\n",
    "\n",
    "# Training function with early stopping\n",
    "def train_model_for_id(\n",
    "    model, train_loader, val_loader, criterion, optimizer, \n",
    "    num_epochs=10, patience=5, device='cpu', obj_id=None\n",
    "):\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training Start for ID {obj_id}\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            # Handle single-sample batches\n",
    "            if inputs.size(0) < 2:\n",
    "                print(\"Switching to eval mode for single-sample batch.\")\n",
    "                model.eval()  # Use eval mode for BatchNorm1d\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                model.train()  # Switch back to train mode\n",
    "                continue\n",
    "\n",
    "            # Normal training process for batches with sufficient samples\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        val_loss = evaluate_model(model, val_loader, criterion, device)\n",
    "\n",
    "        print(f\"ID: {obj_id} - Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "              f\"Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping and model saving logic\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            torch.save(model.state_dict(), f\"sye{obj_id}.pth\")\n",
    "            print(f\"Validation loss improved. Model for ID {obj_id} saved.\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"No improvement for {epochs_without_improvement} epochs.\")\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered for ID {obj_id} after {epoch+1} epochs.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "base_path = \"C:\\\\Users\\\\sakar\\\\OneDrive\\\\mt-datas\\\\synthetic_data\"\n",
    "dataset_name = \"8_correct_relative\"\n",
    "data_2d_subfolder = \"2d_data\"\n",
    "data_3d_subfolder = \"3d_data\"\n",
    "\n",
    "# Construct paths to the data directories\n",
    "data_2d_path = os.path.join(base_path, dataset_name, data_2d_subfolder)\n",
    "data_3d_path = os.path.join(base_path, dataset_name, data_3d_subfolder)\n",
    "\n",
    "# Load the dataset and get data by ID\n",
    "object_dataset_by_id = ObjectDatasetByID(data_2d_path, data_3d_path)\n",
    "data_by_id = object_dataset_by_id.get_data_by_id()\n",
    "\n",
    "# Model parameters\n",
    "input_size = 20\n",
    "output_size = 30\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "patience = 5  # Early stopping patience\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Loop through each unique ID to train and save models\n",
    "for obj_id, (data_2d, data_3d) in data_by_id.items():\n",
    "    dataset = torch.utils.data.TensorDataset(data_2d, data_3d)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "\n",
    "    if train_size == 0 or val_size == 0:\n",
    "        print(f\"Skipping ID {obj_id} due to insufficient data.\")\n",
    "        continue\n",
    "\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    model = PoseEstimationNet(input_size=input_size, output_size=output_size)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(f\"\\nStarting training for ID {obj_id}\")\n",
    "    train_model_for_id(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        num_epochs=num_epochs, patience=patience, device='cpu', obj_id=obj_id\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_path = r\"C:\\Users\\sakar\\OneDrive\\mt-datas\\yolo\\pose_estimation\"\n",
    "filename = \"1_realistic_chair_train_2_yolo_result.csv\"\n",
    "\n",
    "# Construct paths to the data directories\n",
    "data_2d_sample_path = os.path.join(base_path, filename)\n",
    "\n",
    "# Define the function to load the trained model and use it for inference\n",
    "def load_model_and_predict_3d(data_2d_path, model_path=\"sye0.pth\", input_size=20, output_size=30):\n",
    "    # Instantiate the model architecture and load weights\n",
    "    model = PoseEstimationNet(input_size=input_size, output_size=output_size)\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))  # Added `weights_only=True`\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Load the 2D data for inference\n",
    "    try:\n",
    "        df_2d = pd.read_csv(data_2d_path, header=None)\n",
    "        df_2d = df_2d.iloc[:, 1:]  # Drop the ID column\n",
    "        data_2d_tensor = torch.tensor(df_2d.values, dtype=torch.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing 2D data: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Run the model to predict 3D points\n",
    "    with torch.no_grad():\n",
    "        predictions_3d = model(data_2d_tensor)\n",
    "    \n",
    "    print(predictions_3d)\n",
    "    return predictions_3d\n",
    "\n",
    "predictions_3d = load_model_and_predict_3d(data_2d_sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Function to plot 3D corner points from predictions and connect them to form a cube\n",
    "def plot_3d_corners(predictions_3d):\n",
    "    # Check if predictions are available\n",
    "    if predictions_3d is None:\n",
    "        print(\"No predictions to plot.\")\n",
    "        return\n",
    "    \n",
    "    # Extract the last 24 elements for the 8 corner points (each corner has 3 coordinates)\n",
    "    corner_predictions = predictions_3d[:, -24:].view(-1, 8, 3)\n",
    "\n",
    "    # Plot each objectâ€™s corners in a 3D space\n",
    "    for i, corners in enumerate(corner_predictions):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        \n",
    "        # Coordinates of the corners\n",
    "        x, y, z = corners[:, 0], corners[:, 1], corners[:, 2]\n",
    "        ax.scatter(x, y, z, c='b', marker='o')\n",
    "\n",
    "        # Annotate each corner for clarity\n",
    "        for j, (x_coord, y_coord, z_coord) in enumerate(corners):\n",
    "            ax.text(x_coord, y_coord, z_coord, f\"{j}\", color=\"red\")\n",
    "\n",
    "        # Define connections for the cube\n",
    "        connections = [\n",
    "            (0, 1), (1, 2), (2, 3), (3, 0),  # Bottom square\n",
    "            (4, 5), (5, 6), (6, 7), (7, 4),  # Top square\n",
    "            (0, 4), (1, 5), (2, 6), (3, 7)   # Vertical edges connecting squares\n",
    "        ]\n",
    "\n",
    "        # Plot lines for each connection\n",
    "        for start, end in connections:\n",
    "            ax.plot(\n",
    "                [x[start], x[end]],\n",
    "                [y[start], y[end]],\n",
    "                [z[start], z[end]],\n",
    "                'b-'\n",
    "            )\n",
    "\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        plt.title(f\"3D Corner Points and Cube Structure for Object\")\n",
    "        plt.show()\n",
    "\n",
    "# Plot the 3D corners from the predictions\n",
    "plot_3d_corners(predictions_3d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Validate Results with Actual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Define the points as a list of tuples (x, y, z)\n",
    "points = [\n",
    "    (3.049782, -1.4, -4.28893),  # Origin\n",
    "    (3.404064, -0.2259196, -3.91012),\n",
    "    (3.404064, -0.2259196, -4.593021),\n",
    "    (2.711343, -0.2259196, -4.593021),\n",
    "    (2.711343, -0.2259196, -3.91012),\n",
    "    (3.404064, -1.4, -3.91012),\n",
    "    (3.404064, -1.4, -4.593021),\n",
    "    (2.711343, -1.4, -4.593021),\n",
    "    (2.711343, -1.4, -3.91012)\n",
    "]\n",
    "\n",
    "# Define the edges of the cube by connecting the vertices\n",
    "edges = [\n",
    "    (1, 2), (2, 3), (3, 4), (4, 1),  # Top square\n",
    "    (5, 6), (6, 7), (7, 8), (8, 5),  # Bottom square\n",
    "    (1, 5), (2, 6), (3, 7), (4, 8)   # Vertical connections\n",
    "]\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Original 3D cube visualization\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "for i, (x, y, z) in enumerate(points):\n",
    "    if i == 0:\n",
    "        ax1.scatter(x, y, z, color='red', s=100, label=\"Origin\")  # Larger, red point for origin\n",
    "        ax1.text(x, y, z, \"Origin\", color='red')\n",
    "    else:\n",
    "        ax1.scatter(x, y, z, color='blue', s=50)  # Blue points for other points\n",
    "        ax1.text(x, y, z, f\"{i-1}\", color='blue')  # Label from 0 to 7\n",
    "\n",
    "# Draw the edges for the original cube\n",
    "for start, end in edges:\n",
    "    x_line = [points[start][0], points[end][0]]\n",
    "    y_line = [points[start][1], points[end][1]]\n",
    "    z_line = [points[start][2], points[end][2]]\n",
    "    ax1.plot(x_line, y_line, z_line, color=\"black\")\n",
    "\n",
    "# Setting labels and title for the original plot\n",
    "ax1.set_xlabel(\"X Axis\")\n",
    "ax1.set_ylabel(\"Y Axis\")\n",
    "ax1.set_zlabel(\"Z Axis\")\n",
    "ax1.set_title(\"Original 3D Cube Visualization\")\n",
    "\n",
    "# Swapped axes visualization\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "points_swapped = [(z, y, x) for x, y, z in points]  # Swap x and z values\n",
    "for i, (x, y, z) in enumerate(points_swapped):\n",
    "    if i == 0:\n",
    "        ax2.scatter(x, y, z, color='red', s=100, label=\"Origin\")  # Larger, red point for origin\n",
    "        ax2.text(x, y, z, \"Origin\", color='red')\n",
    "    else:\n",
    "        ax2.scatter(x, y, z, color='blue', s=50)  # Blue points for other points\n",
    "        ax2.text(x, y, z, f\"{i-1}\", color='blue')  # Label from 0 to 7\n",
    "\n",
    "# Draw the edges for the swapped cube\n",
    "for start, end in edges:\n",
    "    x_line = [points_swapped[start][0], points_swapped[end][0]]\n",
    "    y_line = [points_swapped[start][1], points_swapped[end][1]]\n",
    "    z_line = [points_swapped[start][2], points_swapped[end][2]]\n",
    "    ax2.plot(x_line, y_line, z_line, color=\"black\")\n",
    "\n",
    "# Setting labels and title for the swapped axes plot\n",
    "ax2.set_xlabel(\"X Axis (original Z)\")\n",
    "ax2.set_ylabel(\"Y Axis\")\n",
    "ax2.set_zlabel(\"Z Axis (original X)\")\n",
    "ax2.set_title(\"3D Cube Visualization with Swapped Axes\")\n",
    "\n",
    "# Show the combined plot with a legend\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Path to the directories\n",
    "base_path_2d = r\"C:\\Users\\sakar\\OneDrive\\mt-datas\\synthetic_data\\8_correct_relative\\2d_data\"\n",
    "base_path_3d = r\"C:\\Users\\sakar\\OneDrive\\mt-datas\\synthetic_data\\8_correct_relative\\3d_data\"\n",
    "\n",
    "# Functions to calculate errors\n",
    "def calculate_mse(predicted, actual):\n",
    "    return np.mean((predicted - actual) ** 2)\n",
    "\n",
    "def calculate_rmse(predicted, actual):\n",
    "    return np.sqrt(calculate_mse(predicted, actual))\n",
    "\n",
    "def calculate_mae(predicted, actual):\n",
    "    return np.mean(np.abs(predicted - actual))\n",
    "\n",
    "# Loop through the 2D files\n",
    "errors = {}\n",
    "for file_name in os.listdir(base_path_2d):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        file_2d_path = os.path.join(base_path_2d, file_name)\n",
    "        file_3d_path = os.path.join(base_path_3d, file_name)\n",
    "\n",
    "        # Check if the corresponding 3D file exists\n",
    "        if not os.path.exists(file_3d_path):\n",
    "            print(f\"3D data file for {file_name} not found. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Predict 3D points using the provided function\n",
    "        predicted_3d = load_model_and_predict_3d(file_2d_path)\n",
    "        if predicted_3d is None:\n",
    "            print(f\"Prediction failed for {file_name}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Read the actual 3D points\n",
    "        try:\n",
    "            actual_3d_df = pd.read_csv(file_3d_path, header=None)\n",
    "            actual_3d = actual_3d_df.iloc[:, 1:].values  # Drop the ID column\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading or processing 3D data for {file_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Initialize error tracking for this file\n",
    "        position_rmse, rotation_rmse, corner_rmse = [], [], []\n",
    "        position_mae, rotation_mae, corner_mae = [], [], []\n",
    "        total_object_rmse, total_object_mae = [], []\n",
    "\n",
    "        # Loop through each row (object) in the file\n",
    "        for i in range(predicted_3d.shape[0]):\n",
    "            pred = predicted_3d[i]\n",
    "            actual = actual_3d[i]\n",
    "\n",
    "            # Ensure conversion to NumPy for each row\n",
    "            if isinstance(pred, torch.Tensor):\n",
    "                pred = pred.numpy()\n",
    "            if isinstance(actual, torch.Tensor):\n",
    "                actual = actual.numpy()\n",
    "\n",
    "            # Extract components\n",
    "            pred_position = pred[:3]\n",
    "            actual_position = actual[:3]\n",
    "\n",
    "            pred_rotation = pred[3:6]\n",
    "            actual_rotation = actual[3:6]\n",
    "\n",
    "            pred_corners = pred[6:].reshape(8, 3)\n",
    "            actual_corners = actual[6:].reshape(8, 3)\n",
    "\n",
    "            # Calculate RMSE and MAE for position, rotation, and corners\n",
    "            pos_rmse = calculate_rmse(pred_position, actual_position)\n",
    "            rot_rmse = calculate_rmse(pred_rotation, actual_rotation)\n",
    "            corner_rmse_values = [calculate_rmse(pred_corners[j], actual_corners[j]) for j in range(8)]\n",
    "            \n",
    "            pos_mae = calculate_mae(pred_position, actual_position)\n",
    "            rot_mae = calculate_mae(pred_rotation, actual_rotation)\n",
    "            corner_mae_values = [calculate_mae(pred_corners[j], actual_corners[j]) for j in range(8)]\n",
    "\n",
    "            # Total RMSE and MAE for this object\n",
    "            object_rmse = pos_rmse + rot_rmse + sum(corner_rmse_values)\n",
    "            object_mae = pos_mae + rot_mae + sum(corner_mae_values)\n",
    "\n",
    "            # Append errors\n",
    "            position_rmse.append(pos_rmse)\n",
    "            rotation_rmse.append(rot_rmse)\n",
    "            corner_rmse.append(sum(corner_rmse_values) / 8)  # Avg corner RMSE\n",
    "            \n",
    "            position_mae.append(pos_mae)\n",
    "            rotation_mae.append(rot_mae)\n",
    "            corner_mae.append(sum(corner_mae_values) / 8)  # Avg corner MAE\n",
    "            \n",
    "            total_object_rmse.append(object_rmse)\n",
    "            total_object_mae.append(object_mae)\n",
    "\n",
    "        # Aggregate RMSE and MAE for the file\n",
    "        file_rmse = {\n",
    "            \"position\": np.mean(position_rmse),\n",
    "            \"rotation\": np.mean(rotation_rmse),\n",
    "            \"corners\": np.mean(corner_rmse),\n",
    "            \"total\": np.mean(total_object_rmse),\n",
    "        }\n",
    "        file_mae = {\n",
    "            \"position\": np.mean(position_mae),\n",
    "            \"rotation\": np.mean(rotation_mae),\n",
    "            \"corners\": np.mean(corner_mae),\n",
    "            \"total\": np.mean(total_object_mae),\n",
    "        }\n",
    "\n",
    "        # Save results\n",
    "        errors[file_name] = {\n",
    "            \"RMSE\": file_rmse,\n",
    "            \"MAE\": file_mae,\n",
    "        }\n",
    "\n",
    "        print(f\"Errors for {file_name}:\\nRMSE: {file_rmse}\\nMAE: {file_mae}\")\n",
    "\n",
    "# Display all errors\n",
    "errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "def visualize_errors_one_file(file_name, predicted_3d, actual_3d):\n",
    "    if file_name not in errors:\n",
    "        print(f\"No errors found for {file_name}.\")\n",
    "        return\n",
    "\n",
    "    # Extract RMSE and MAE for the file\n",
    "    file_rmse = errors[file_name][\"RMSE\"]\n",
    "    file_mae = errors[file_name][\"MAE\"]\n",
    "\n",
    "    # Plot RMSE and MAE as bar charts\n",
    "    labels = [\"Position\", \"Rotation\", \"Corners\", \"Total\"]\n",
    "    rmse_values = [file_rmse[\"position\"], file_rmse[\"rotation\"], file_rmse[\"corners\"], file_rmse[\"total\"]]\n",
    "    mae_values = [file_mae[\"position\"], file_mae[\"rotation\"], file_mae[\"corners\"], file_mae[\"total\"]]\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - width / 2, rmse_values, width, label=\"RMSE\")\n",
    "    plt.bar(x + width / 2, mae_values, width, label=\"MAE\")\n",
    "\n",
    "    plt.xlabel(\"Error Components\")\n",
    "    plt.ylabel(\"Error Value\")\n",
    "    plt.title(f\"Error Metrics for {file_name}\")\n",
    "    plt.xticks(x, labels)\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"y\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 3D scatter plot for predicted vs. actual 3D points\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    for i in range(predicted_3d.shape[0]):\n",
    "        pred = predicted_3d[i]\n",
    "        actual = actual_3d[i]\n",
    "\n",
    "        pred_corners = pred[6:].reshape(8, 3)\n",
    "        actual_corners = actual[6:].reshape(8, 3)\n",
    "\n",
    "        # Plot predicted corners in blue\n",
    "        ax.scatter(pred_corners[:, 0], pred_corners[:, 1], pred_corners[:, 2], color=\"blue\", label=\"Predicted\" if i == 0 else \"\")\n",
    "        # Plot actual corners in green\n",
    "        ax.scatter(actual_corners[:, 0], actual_corners[:, 1], actual_corners[:, 2], color=\"green\", label=\"Actual\" if i == 0 else \"\")\n",
    "\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\")\n",
    "    ax.set_title(f\"3D Points Comparison for {file_name}\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "file_name = \"2450.csv\"\n",
    "predicted_3d = load_model_and_predict_3d(os.path.join(base_path_2d, file_name))\n",
    "actual_3d_df = pd.read_csv(os.path.join(base_path_3d, file_name), header=None)\n",
    "actual_3d = actual_3d_df.iloc[:, 1:].values\n",
    "\n",
    "visualize_errors_one_file(file_name, predicted_3d, actual_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def visualize_errors_all_files_stacked(errors):\n",
    "    # Extract errors into DataFrame\n",
    "    data = []\n",
    "    for file_name, metrics in errors.items():\n",
    "        rmse = metrics[\"RMSE\"]\n",
    "        mae = metrics[\"MAE\"]\n",
    "        data.append([\n",
    "            file_name,\n",
    "            rmse[\"position\"], rmse[\"rotation\"], rmse[\"corners\"],\n",
    "            mae[\"position\"], mae[\"rotation\"], mae[\"corners\"]\n",
    "        ])\n",
    "\n",
    "    columns = [\"File\", \"RMSE_Position\", \"RMSE_Rotation\", \"RMSE_Corners\",\n",
    "               \"MAE_Position\", \"MAE_Rotation\", \"MAE_Corners\"]\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    x = np.arange(len(df))\n",
    "    \n",
    "    # Generate plots\n",
    "    # 4 for MAE\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"MAE_Corners\"], color=\"lightgreen\", label=\"Corners\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.title(\"MAE Errors for Corners\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"MAE_Position\"], color=\"skyblue\", label=\"Position\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.title(\"MAE Errors for Position\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"MAE_Rotation\"], color=\"orange\", label=\"Rotation\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.title(\"MAE Errors for Rotation\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"MAE_Position\"], color=\"skyblue\", label=\"Position\")\n",
    "    plt.bar(x, df[\"RMSE_Corners\"], bottom=df[\"RMSE_Position\"] , color=\"lightgreen\", label=\"Corners\")\n",
    "    plt.bar(x, df[\"RMSE_Rotation\"], bottom=df[\"RMSE_Position\"]+ df[\"RMSE_Corners\"], color=\"orange\", label=\"Rotation\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.title(\"MAE Total Errors (Stacked)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 4 for RMSE\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"RMSE_Corners\"], color=\"lightgreen\", label=\"Corners\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"RMSE Errors for Corners\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"RMSE_Position\"], color=\"skyblue\", label=\"Position\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"RMSE Errors for Position\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"RMSE_Rotation\"], color=\"orange\", label=\"Rotation\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"RMSE Errors for Rotation\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"RMSE_Position\"], color=\"skyblue\", label=\"Position\")\n",
    "    plt.bar(x, df[\"RMSE_Corners\"], bottom=df[\"RMSE_Position\"] , color=\"lightgreen\", label=\"Corners\")\n",
    "    plt.bar(x, df[\"RMSE_Rotation\"], bottom=df[\"RMSE_Position\"]+ df[\"RMSE_Corners\"], color=\"orange\", label=\"Rotation\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"RMSE Total Errors (Stacked)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Example: Visualize stacked RMSE and MAE errors across all files\n",
    "visualize_errors_all_files_stacked(errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Randomly select 10 files from the errors dictionary\n",
    "selected_files = random.sample(list(errors.keys()), 10)\n",
    "\n",
    "# Extract the selected errors into a new dictionary\n",
    "selected_errors = {file: errors[file] for file in selected_files}\n",
    "\n",
    "print(\"Selected Files for Visualization:\")\n",
    "print(selected_files)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def visualize_selected_errors_stacked(selected_errors):\n",
    "    # Extract errors into DataFrame\n",
    "    data = []\n",
    "    for file_name, metrics in selected_errors.items():\n",
    "        rmse = metrics[\"RMSE\"]\n",
    "        mae = metrics[\"MAE\"]\n",
    "        data.append([\n",
    "            file_name,\n",
    "            rmse[\"position\"], rmse[\"rotation\"], rmse[\"corners\"],\n",
    "            mae[\"position\"], mae[\"rotation\"], mae[\"corners\"]\n",
    "        ])\n",
    "\n",
    "    columns = [\"File\", \"RMSE_Position\", \"RMSE_Rotation\", \"RMSE_Corners\",\"MAE_Position\", \"MAE_Rotation\", \"MAE_Corners\"]\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    x = np.arange(len(df))\n",
    "    \n",
    "    # 4 for MAE\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"MAE_Corners\"], color=\"lightgreen\", label=\"Corners\")\n",
    "    plt.xticks(x, df[\"File\"], rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.title(\"MAE Errors for Corners\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"MAE_Position\"], color=\"skyblue\", label=\"Position\")\n",
    "    plt.xticks(x, df[\"File\"], rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.title(\"MAE Errors for Position\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"MAE_Rotation\"], color=\"orange\", label=\"Rotation\")\n",
    "    plt.xticks(x, df[\"File\"], rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.title(\"MAE Errors for Rotation\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"MAE_Position\"], color=\"skyblue\", label=\"Position\")\n",
    "    plt.bar(x, df[\"MAE_Corners\"], bottom=df[\"MAE_Position\"], color=\"lightgreen\", label=\"Corners\")\n",
    "    plt.bar(x, df[\"MAE_Rotation\"], bottom=df[\"MAE_Position\"] + df[\"MAE_Corners\"], color=\"orange\", label=\"Rotation\")\n",
    "    \n",
    "    plt.xticks(x, df[\"File\"], rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.title(\"MAE Total Errors (Stacked)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 4 for RMSE\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"RMSE_Corners\"], color=\"lightgreen\", label=\"Corners\")\n",
    "    plt.xticks(x, df[\"File\"], rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"RMSE Errors for Corners\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"RMSE_Position\"], color=\"skyblue\", label=\"Position\")\n",
    "    plt.xticks(x, df[\"File\"], rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"RMSE Errors for Position\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"RMSE_Rotation\"], color=\"orange\", label=\"Rotation\")\n",
    "    plt.xticks(x, df[\"File\"], rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"RMSE Errors for Rotation\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(x, df[\"RMSE_Position\"], color=\"skyblue\", label=\"Position\")\n",
    "    plt.bar(x, df[\"MAE_Corners\"], bottom=df[\"MAE_Position\"], color=\"lightgreen\", label=\"Corners\")\n",
    "    plt.bar(x, df[\"MAE_Rotation\"], bottom=df[\"MAE_Position\"] + df[\"MAE_Corners\"], color=\"orange\", label=\"Rotation\")\n",
    "    plt.xticks(x, df[\"File\"], rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.title(\"RMSE Total Errors (Stacked)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the errors for the selected files\n",
    "visualize_selected_errors_stacked(selected_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to identify outliers and median\n",
    "def identify_outliers_and_median(errors, category):\n",
    "    data = []\n",
    "    for file_name, metrics in errors.items():\n",
    "        rmse = metrics[\"RMSE\"]\n",
    "        mae = metrics[\"MAE\"]\n",
    "        data.append([\n",
    "            file_name,\n",
    "            rmse[\"position\"], rmse[\"rotation\"], rmse[\"corners\"],\n",
    "            mae[\"position\"], mae[\"rotation\"], mae[\"corners\"],\n",
    "            rmse[\"position\"] + rmse[\"rotation\"] + rmse[\"corners\"],  # Total RMSE\n",
    "            mae[\"position\"] + mae[\"rotation\"] + mae[\"corners\"],    # Total MAE\n",
    "        ])\n",
    "    \n",
    "    columns = [\"File\", \"RMSE_Position\", \"RMSE_Rotation\", \"RMSE_Corners\",\n",
    "               \"MAE_Position\", \"MAE_Rotation\", \"MAE_Corners\",\n",
    "               \"RMSE_Total\", \"MAE_Total\"]\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    # Get top 10 highest, lowest, and median for the selected category\n",
    "    top_10_highest = df.nlargest(10, category)\n",
    "    top_10_lowest = df.nsmallest(10, category)\n",
    "    median_start = len(df) // 2 - 5\n",
    "    median_end = median_start + 10\n",
    "    median_10 = df.sort_values(by=category).iloc[median_start:median_end]\n",
    "\n",
    "    return top_10_highest, top_10_lowest, median_10\n",
    "\n",
    "# Function to visualize outliers and median\n",
    "def visualize_outliers_and_median(top_10_high, top_10_low, median_10, category, metric_name):\n",
    "    # Combine high, median, and low into a single DataFrame for plotting\n",
    "    combined = pd.concat([top_10_high, median_10, top_10_low])\n",
    "    labels = combined[\"File\"]\n",
    "    values = combined[category]\n",
    "\n",
    "    # Colors: Orange for highest, Green for median, Skyblue for lowest\n",
    "    colors = (\n",
    "        ['orange'] * len(top_10_high) +\n",
    "        ['green'] * len(median_10) +\n",
    "        ['skyblue'] * len(top_10_low)\n",
    "    )\n",
    "\n",
    "    # Bar Plot\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    bars = plt.bar(labels, values, color=colors)\n",
    "\n",
    "    # Create a custom legend\n",
    "    legend_handles = [\n",
    "        bars[0],  # Example bar for highest (orange)\n",
    "        bars[len(top_10_high)],  # Example bar for median (green)\n",
    "        bars[-1],  # Example bar for lowest (skyblue)\n",
    "    ]\n",
    "    legend_labels = [\"Top 10 Highest\", \"10 Median\", \"Top 10 Lowest\"]\n",
    "\n",
    "    # Plot customization\n",
    "    plt.xlabel(\"CSV Files\")\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title(f\"Outliers and Median for {metric_name} - {category}\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.legend(legend_handles, legend_labels)\n",
    "    plt.show()\n",
    "\n",
    "# Loop through all error categories including totals and generate plots\n",
    "categories = [\n",
    "    \"MAE_Position\", \"MAE_Rotation\", \"MAE_Corners\", \"MAE_Total\",\n",
    "    \"RMSE_Position\", \"RMSE_Rotation\", \"RMSE_Corners\", \"RMSE_Total\"\n",
    "]\n",
    "\n",
    "for category in categories:\n",
    "    metric_name = \"MAE\" if \"MAE\" in category else \"RMSE\"\n",
    "    print(f\"\\nProcessing Outliers and Median for {category}\")\n",
    "    \n",
    "    # Identify outliers and median\n",
    "    top_10_high, top_10_low, median_10 = identify_outliers_and_median(errors, category)\n",
    "    \n",
    "    # Visualize outliers and median\n",
    "    visualize_outliers_and_median(top_10_high, top_10_low, median_10, category, metric_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input coordinates (X and Z components)\n",
    "points_xz = np.array([\n",
    "    [-3.1509, 5.7967],  # P0\n",
    "    [-3.0486, 5.2867],  # P1\n",
    "    [-4.3261, 4.4202],  # P2\n",
    "    [-4.3691, 4.9874]   # P3\n",
    "])\n",
    "\n",
    "# Calculate the vectors\n",
    "vec_p1_p0 = points_xz[0] - points_xz[1]  # P1->P0\n",
    "vec_p2_p1 = points_xz[1] - points_xz[2]  # P2->P1\n",
    "\n",
    "# Function to calculate angle with a given axis\n",
    "def calculate_angle(vector, axis):\n",
    "    cos_theta = np.dot(vector, axis) / np.linalg.norm(vector)  # Cosine of the angle\n",
    "    angle_radians = np.arccos(cos_theta)  # Angle in radians\n",
    "    # Determine the direction of the angle (clockwise or counterclockwise)\n",
    "    cross_product = vector[0] * axis[1] - vector[1] * axis[0]  # 2D cross product scalar\n",
    "    if cross_product < 0:  # Negative cross product means clockwise\n",
    "        angle_radians = -angle_radians\n",
    "    return angle_radians\n",
    "\n",
    "# Calculate angles\n",
    "z_axis = np.array([0, 1])  # Z-axis in the X-Z plane\n",
    "x_axis = np.array([1, 0])  # X-axis in the X-Z plane\n",
    "\n",
    "angle_radians_p1_p0 = calculate_angle(vec_p1_p0, z_axis)  # Align P1->P0 with Z-axis\n",
    "angle_radians_p2_p1 = calculate_angle(vec_p2_p1, x_axis)  # Align P2->P1 with X-axis\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Plot the points\n",
    "for i, point in enumerate(points_xz):\n",
    "    plt.scatter(point[0], point[1], label=f\"P{i}\")\n",
    "    plt.text(point[0], point[1], f\"P{i}\", fontsize=9)\n",
    "\n",
    "# Plot the vectors\n",
    "plt.quiver(points_xz[1, 0], points_xz[1, 1], vec_p1_p0[0], vec_p1_p0[1], angles='xy', scale_units='xy', scale=1, color='b', label=\"P1->P0\")\n",
    "plt.quiver(points_xz[2, 0], points_xz[2, 1], vec_p2_p1[0], vec_p2_p1[1], angles='xy', scale_units='xy', scale=1, color='g', label=\"P2->P1\")\n",
    "\n",
    "# Add axis lines\n",
    "plt.axhline(0, color='gray', linewidth=0.8)\n",
    "plt.axvline(0, color='gray', linewidth=0.8)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel(\"X (Right)\")\n",
    "plt.ylabel(\"Z (Forward)\")\n",
    "plt.title(\"2D Visualization on X-Z Plane (Aligning P1->P0 to Z-axis and P2->P1 to X-axis)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.axis('equal')  # Keep proportions equal\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "print(\"Vector P1->P0:\", vec_p1_p0)\n",
    "print(\"Rotation Angle (radians) to align P1->P0 with Z-axis:\", angle_radians_p1_p0)\n",
    "print(\"Rotation Angle (degrees) to align P1->P0 with Z-axis:\", np.degrees(angle_radians_p1_p0))\n",
    "print(\"Vector P2->P1:\", vec_p2_p1)\n",
    "print(\"Rotation Angle (radians) to align P2->P1 with X-axis:\", angle_radians_p2_p1)\n",
    "print(\"Rotation Angle (degrees) to align P2->P1 with X-axis:\", np.degrees(angle_radians_p2_p1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
